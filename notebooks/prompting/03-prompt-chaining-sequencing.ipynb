{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Chaining and Sequencing Tutorial\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial delves into the powerful techniques of prompt chaining and sequencing when working with large language models. We'll demonstrate these concepts using Amazon Nova via OpenRouter and LangChain, showing you how to create sophisticated, multi-step AI-driven processes.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "As AI applications grow in complexity, it becomes crucial to break down intricate tasks into manageable steps. Prompt chaining and sequencing provide a framework for guiding language models through a series of interconnected prompts, resulting in more structured and controlled outputs. This approach is invaluable for tasks requiring multiple stages of processing or decision-making.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. **Basic Prompt Chaining**: Linking outputs from one prompt to inputs of another.\n",
        "2. **Sequential Prompting**: Designing a logical progression of prompts to guide the AI through multi-step processes.\n",
        "3. **Dynamic Prompt Generation**: Utilizing the output of one prompt to adaptively create the next prompt.\n",
        "4. **Error Handling and Validation**: Implementing safeguards and quality checks within the prompt chain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from os import getenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
        "    openai_api_base=getenv(\"OPENROUTER_BASE_URL\"),\n",
        "    model_name=\"amazon/nova-pro-v1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Prompt Chaining\n",
        "\n",
        "Let's start with a simple example of prompt chaining. We'll create two prompts: one to generate a short story, and another to summarize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Story: In the year 2150, humanity had colonized the galaxy, but at a great cost. The use of advanced technology had depleted Earth's resources, leaving it a barren wasteland. As the last remnants of humanity fled to the stars, a small group of scientists remained behind, determined to find a way to restore the planet's ecosystem using experimental technology. Little did they know, their actions would awaken a long-dormant force that threatened to consume not only Earth, but the entire galaxy.\n",
            "\n",
            "Summary: In 2150, after humanity colonized the galaxy and left Earth a barren wasteland, a group of scientists stayed behind to restore the planet's ecosystem, inadvertently awakening a dormant force that threatened the entire galaxy.\n"
          ]
        }
      ],
      "source": [
        "# Define prompt templates\n",
        "story_prompt = PromptTemplate(\n",
        "    input_variables=[\"genre\"], template=\"Write a short {genre} story in 3-4 sentences.\"\n",
        ")\n",
        "\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"story\"],\n",
        "    template=\"Summarize the following story in one sentence:\\n{story}\",\n",
        ")\n",
        "\n",
        "# Chain the prompts\n",
        "\n",
        "\n",
        "def story_chain(genre):\n",
        "    \"\"\"Generate a story and its summary based on a given genre.\n",
        "\n",
        "    Args:\n",
        "        genre (str): The genre of the story to generate.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the generated story and its summary.\n",
        "    \"\"\"\n",
        "    story = (story_prompt | llm).invoke({\"genre\": genre}).content\n",
        "    summary = (summary_prompt | llm).invoke({\"story\": story}).content\n",
        "    return story, summary\n",
        "\n",
        "\n",
        "# Test the chain\n",
        "genre = \"science fiction\"\n",
        "story, summary = story_chain(genre)\n",
        "print(f\"Story: {story}\\n\\nSummary: {summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential Prompting\n",
        "\n",
        "Now, let's create a more complex sequence of prompts for a multi-step analysis task. We'll analyze a given text for its main theme, tone, and key takeaways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Theme: The main theme of the text is the dual-edged nature of artificial intelligence\u2014highlighting both its promising potential to revolutionize industries and enhance daily life, and the significant ethical concerns and risks it poses, such as privacy issues, job displacement, and potential misuse. The text emphasizes the importance of cautious and foresighted development of AI to maximize its benefits while minimizing its risks.\n",
            "\n",
            "Tone: The overall tone of the text is cautious and measured. It acknowledges the potential benefits of artificial intelligence (AI) while also highlighting the significant concerns and ethical questions that accompany its rapid advancement. The text calls for a balanced approach to AI development, emphasizing the need for caution, foresight, and ethical consideration to ensure that the technology\u2019s advantages are realized without compromising on safety, privacy, and societal well-being.\n",
            "\n",
            "Takeaways: Certainly! Here are the key takeaways from the provided text:\n",
            "\n",
            "### Key Takeaways:\n",
            "\n",
            "1. **Dual-Edged Nature of AI**:\n",
            "   - **Promising Potential**:\n",
            "     - AI has the potential to revolutionize various industries.\n",
            "     - It can significantly enhance and improve daily life.\n",
            "   - **Significant Concerns**:\n",
            "     - Ethical questions and risks accompany AI\u2019s rapid advancement.\n",
            "     - Key concerns include privacy issues, job displacement, and potential misuse.\n",
            "\n",
            "2. **Cautious and Measured Tone**:\n",
            "   - The text adopts a cautious and measured tone, acknowledging both the benefits and risks of AI.\n",
            "   - It stresses the importance of a balanced perspective on AI development.\n",
            "\n",
            "3. **Need for Caution and Foresight**:\n",
            "   - AI development should be approached with caution to mitigate risks.\n",
            "   - Foresight is essential to anticipate and address potential issues before they become problematic.\n",
            "\n",
            "4. **Ethical Considerations**:\n",
            "   - Ethical questions must be at the forefront of AI development.\n",
            "   - Ensuring safety, privacy, and societal well-being should be paramount.\n",
            "\n",
            "5. **Balanced Approach**:\n",
            "   - The text calls for a balanced approach to AI development.\n",
            "   - Maximizing AI\u2019s benefits while minimizing its risks is the goal.\n",
            "\n",
            "6. **Stakeholder Responsibility**:\n",
            "   - There is an implicit call to action for developers, policymakers, and society at large to take responsibility in guiding AI development.\n",
            "   - Collaborative efforts are necessary to navigate the complexities of AI.\n",
            "\n",
            "In summary, the text underscores the transformative potential of AI while urging a cautious, ethical, and foresighted approach to its development to ensure that its advantages are fully realized without compromising on critical societal values.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define prompt templates for each step\n",
        "theme_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Identify the main theme of the following text:\\n{text}\",\n",
        ")\n",
        "\n",
        "tone_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Describe the overall tone of the following text:\\n{text}\",\n",
        ")\n",
        "\n",
        "takeaway_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\", \"theme\", \"tone\"],\n",
        "    template=\"Given the following text with the main theme '{theme}' and tone '{tone}', what are the key takeaways?\\n{text}\",\n",
        ")\n",
        "\n",
        "\n",
        "def analyze_text(text):\n",
        "    \"\"\"Perform a multi-step analysis of a given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to analyze.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the theme, tone, and key takeaways of the text.\n",
        "    \"\"\"\n",
        "    theme = (theme_prompt | llm).invoke({\"text\": text}).content\n",
        "    tone = (tone_prompt | llm).invoke({\"text\": text}).content\n",
        "    takeaways = (\n",
        "        (takeaway_prompt | llm)\n",
        "        .invoke({\"text\": text, \"theme\": theme, \"tone\": tone})\n",
        "        .content\n",
        "    )\n",
        "    return {\"theme\": theme, \"tone\": tone, \"takeaways\": takeaways}\n",
        "\n",
        "\n",
        "# Test the sequential prompting\n",
        "sample_text = \"The rapid advancement of artificial intelligence has sparked both excitement and concern among experts. While AI promises to revolutionize industries and improve our daily lives, it also raises ethical questions about privacy, job displacement, and the potential for misuse. As we stand on the brink of this technological revolution, it's crucial that we approach AI development with caution and foresight, ensuring that its benefits are maximized while its risks are minimized.\"\n",
        "\n",
        "analysis = analyze_text(sample_text)\n",
        "for key, value in analysis.items():\n",
        "    print(f\"{key.capitalize()}: {value}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dynamic Prompt Generation\n",
        "\n",
        "In this section, we'll create a dynamic question-answering system that generates follow-up questions based on previous answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1: What are the potential applications of quantum computing?\n",
            "A1: Quantum computing has potential applications in cryptography, drug discovery, optimization problems, financial modeling, machine learning, and simulating quantum systems.\n",
            "\n",
            "Q2: Certainly! Here's a relevant follow-up question:\n",
            "\n",
            "\"Can you elaborate on how quantum computing specifically enhances the processes involved in drug discovery and optimization problems?\"\n",
            "\n",
            "This question delves deeper into two of the applications mentioned, seeking a more detailed explanation of the benefits and mechanisms through which quantum computing contributes to these fields.\n",
            "A2: Quantum computing enhances drug discovery and optimization by efficiently simulating molecular interactions and predicting chemical properties, which are computationally intensive for classical computers. This leads to faster identification of potential drug candidates and more accurate predictions of their efficacy and side effects.\n",
            "\n",
            "Q3: Certainly! Here's a relevant follow-up question:\n",
            "\n",
            "\"Could you provide specific examples of molecular simulations or chemical property predictions that have been successfully accomplished using quantum computing, and how these achievements have translated into tangible advancements in drug discovery and development?\"\n",
            "A3: Specific examples include simulating the behavior of small molecules like hydrogen (H\u2082) and lithium hydride (LiH), predicting molecular properties such as binding affinities, and modeling enzyme-substrate interactions. These advancements have enabled more accurate identification of potential drug candidates, reduced development timelines, and enhanced understanding of molecular mechanisms, leading to more effective therapeutic strategies.\n",
            "\n",
            "Q4: Certainly! Here's a relevant follow-up question:\n",
            "\n",
            "\"Can you elaborate on the specific quantum computing algorithms or techniques that have been employed in these molecular simulations and property predictions, and discuss any challenges or limitations that researchers have encountered in applying quantum computing to drug discovery and development?\"\n",
            "A4: Quantum computing algorithms like VQE (Variational Quantum Eigensolver) and QAOA (Quantum Approximate Optimization Algorithm) are used in molecular simulations. Challenges include error rates, limited qubit count, and algorithm scalability.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define prompt templates\n",
        "answer_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Answer the following question concisely:\\n{question}\",\n",
        ")\n",
        "\n",
        "follow_up_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"],\n",
        "    template=\"Based on the question '{question}' and the answer '{answer}', generate a relevant follow-up question.\",\n",
        ")\n",
        "\n",
        "\n",
        "def dynamic_qa(initial_question, num_follow_ups=3):\n",
        "    \"\"\"Conduct a dynamic Q&A session with follow-up questions.\n",
        "\n",
        "    Args:\n",
        "        initial_question (str): The initial question to start the Q&A session.\n",
        "        num_follow_ups (int): The number of follow-up questions to generate.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries containing questions and answers.\n",
        "    \"\"\"\n",
        "    qa_chain = []\n",
        "    current_question = initial_question\n",
        "\n",
        "    for _ in range(num_follow_ups + 1):  # +1 for the initial question\n",
        "        answer = (answer_prompt | llm).invoke({\"question\": current_question}).content\n",
        "        qa_chain.append({\"question\": current_question, \"answer\": answer})\n",
        "\n",
        "        if _ < num_follow_ups:  # Generate follow-up for all but the last iteration\n",
        "            current_question = (\n",
        "                (follow_up_prompt | llm)\n",
        "                .invoke({\"question\": current_question, \"answer\": answer})\n",
        "                .content\n",
        "            )\n",
        "\n",
        "    return qa_chain\n",
        "\n",
        "\n",
        "# Test the dynamic Q&A system\n",
        "initial_question = \"What are the potential applications of quantum computing?\"\n",
        "qa_session = dynamic_qa(initial_question)\n",
        "\n",
        "for i, qa in enumerate(qa_session):\n",
        "    print(f\"Q{i+1}: {qa['question']}\")\n",
        "    print(f\"A{i+1}: {qa['answer']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error Handling and Validation\n",
        "\n",
        "In this final section, we'll implement error handling and validation in our prompt chains to make them more robust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final result for topic '\u0110i\u1ec7n Bi\u00ean Ph\u1ee7': 1954\n"
          ]
        }
      ],
      "source": [
        "# Define prompt templates\n",
        "generate_prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Generate a 4-digit number related to the topic: {topic}. Respond with ONLY the number, no additional text.\",\n",
        ")\n",
        "\n",
        "validate_prompt = PromptTemplate(\n",
        "    input_variables=[\"number\", \"topic\"],\n",
        "    template=\"Is the number {number} truly related to the topic '{topic}'? Answer with 'Yes' or 'No' and explain why.\",\n",
        ")\n",
        "\n",
        "\n",
        "def extract_number(text):\n",
        "    \"\"\"Extract a 4-digit number from the given text.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text to extract the number from.\n",
        "\n",
        "    Returns:\n",
        "        str or None: The extracted 4-digit number, or None if no valid number is found.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"\\b\\d{4}\\b\", text)\n",
        "    return match.group() if match else None\n",
        "\n",
        "\n",
        "def robust_number_generation(topic, max_attempts=3):\n",
        "    \"\"\"Generate a topic-related number with validation and error handling.\n",
        "\n",
        "    Args:\n",
        "        topic (str): The topic to generate a number for.\n",
        "        max_attempts (int): Maximum number of generation attempts.\n",
        "\n",
        "    Returns:\n",
        "        str: A validated 4-digit number or an error message.\n",
        "    \"\"\"\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = (generate_prompt | llm).invoke({\"topic\": topic}).content\n",
        "            number = extract_number(response)\n",
        "\n",
        "            if not number:\n",
        "                raise ValueError(\n",
        "                    f\"Failed to extract a 4-digit number from the response: {response}\"\n",
        "                )\n",
        "\n",
        "            # Validate the relevance\n",
        "            validation = (\n",
        "                (validate_prompt | llm)\n",
        "                .invoke({\"number\": number, \"topic\": topic})\n",
        "                .content\n",
        "            )\n",
        "            if validation.lower().startswith(\"yes\"):\n",
        "                return number\n",
        "            else:\n",
        "                print(\n",
        "                    f\"Attempt {attempt + 1}: Number {number} was not validated. Reason: {validation}\"\n",
        "                )\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "\n",
        "    return \"Failed to generate a valid number after multiple attempts.\"\n",
        "\n",
        "\n",
        "# Test the robust number generation\n",
        "topic = \"\u0110i\u1ec7n Bi\u00ean Ph\u1ee7\"\n",
        "result = robust_number_generation(topic)\n",
        "print(f\"Final result for topic '{topic}': {result}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
