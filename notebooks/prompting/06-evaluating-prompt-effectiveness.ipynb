{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating Prompt Effectiveness Tutorial\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial delves into strategies and methodologies for assessing the efficacy of prompts used in AI language models. We'll examine a range of metrics for quantifying prompt performance and explore both hands-on and automated evaluation approaches.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "With prompt engineering playing an increasingly vital role in AI applications, it's crucial to develop robust methods for gauging prompt effectiveness. This empowers developers and researchers to fine-tune their prompts, resulting in enhanced AI model performance and more dependable outputs.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. Quantitative metrics for assessing prompt performance.\n",
        "2. Hands-on evaluation methodologies.\n",
        "3. Automated assessment techniques.\n",
        "4. Real-world examples utilizing Amazon Nova via OpenRouter and LangChain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import getenv\n",
        "\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
        "    openai_api_base=getenv(\"OPENROUTER_BASE_URL\"),\n",
        "    model_name=\"bedrock/nova-lite-v1\",\n",
        ")\n",
        "\n",
        "# Initialize sentence transformer for semantic similarity\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "\n",
        "def semantic_similarity(text1, text2):\n",
        "    \"\"\"Calculate semantic similarity between two texts using cosine similarity.\"\"\"\n",
        "    embeddings = sentence_model.encode([text1, text2])\n",
        "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics for Measuring Prompt Performance\n",
        "\n",
        "Let's define some key metrics for evaluating prompt effectiveness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relevance_score(response, expected_content):\n",
        "    \"\"\"Calculate relevance score based on semantic similarity to expected content.\"\"\"\n",
        "    return semantic_similarity(response, expected_content)\n",
        "\n",
        "\n",
        "def consistency_score(responses):\n",
        "    \"\"\"Calculate consistency score based on similarity between multiple responses.\"\"\"\n",
        "    if len(responses) < 2:\n",
        "        return 1.0  # Perfect consistency if there's only one response\n",
        "    similarities = []\n",
        "    for i in range(len(responses)):\n",
        "        for j in range(i + 1, len(responses)):\n",
        "            similarities.append(semantic_similarity(responses[i], responses[j]))\n",
        "    return np.mean(similarities)\n",
        "\n",
        "\n",
        "def specificity_score(response):\n",
        "    \"\"\"Calculate specificity score based on response length and unique word count.\"\"\"\n",
        "    words = response.split()\n",
        "    unique_words = set(words)\n",
        "    return len(unique_words) / len(words) if words else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manual Evaluation Techniques\n",
        "\n",
        "Manual evaluation involves human assessment of prompt-response pairs. Let's create a function to simulate this process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: Explain the concept of machine learning in simple terms.\n",
            "Response: Imagine you have a puppy you're trying to teach to sit.  Instead of explicitly telling it *how* to sit (step-by-step instructions), you show it examples: when it gets close to sitting, you give it a treat.  Over time, the puppy learns to associate the action of sitting with the reward, and eventually sits on command without needing further instruction.\n",
            "\n",
            "Machine learning is similar.  Instead of giving a computer explicit instructions for every task, we give it lots of examples (data) and let it figure out the patterns and rules on its own.  If it does well (makes accurate predictions or takes the right actions), we \"reward\" it by adjusting its internal \"rules\" slightly.  Through this process of learning from examples and feedback, the computer becomes better at the task over time, just like the puppy.\n",
            "\n",
            "So basically, machine learning is about teaching computers to learn from data without being explicitly programmed.\n",
            "\n",
            "\n",
            "Evaluation Criteria:\n",
            "Clarity: 5.0/10\n",
            "Accuracy: 5.0/10\n",
            "Simplicity: 5.0/10\n",
            "\n",
            "Additional Comments:\n",
            "Comments: \n"
          ]
        }
      ],
      "source": [
        "def manual_evaluation(prompt, response, criteria):\n",
        "    \"\"\"Simulate manual evaluation of a prompt-response pair.\"\"\"\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(\"\\nEvaluation Criteria:\")\n",
        "    for criterion in criteria:\n",
        "        score = float(input(f\"Score for {criterion} (0-10): \"))\n",
        "        print(f\"{criterion}: {score}/10\")\n",
        "    print(\"\\nAdditional Comments:\")\n",
        "    comments = input(\"Enter any additional comments: \")\n",
        "    print(f\"Comments: {comments}\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Explain the concept of machine learning in simple terms.\"\n",
        "response = llm.invoke(prompt).content\n",
        "criteria = [\"Clarity\", \"Accuracy\", \"Simplicity\"]\n",
        "manual_evaluation(prompt, response, criteria)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Automated Evaluation Techniques\n",
        "\n",
        "Now, let's implement some automated evaluation techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: What are the three main types of machine learning?\n",
            "Response: The three main types of machine learning are:\n",
            "\n",
            "1. **Supervised Learning:**  The algorithm learns from a labeled dataset, meaning the data includes both the input features and the desired output (the \"label\").  The algorithm learns to map inputs to outputs. Examples include image classification (input: image; output: object label) and spam detection (input: email; output: spam/not spam).\n",
            "\n",
            "2. **Unsupervised Learning:** The algorithm learns from an unlabeled dataset, meaning the data only includes input features without corresponding outputs. The algorithm tries to find patterns, structure, or relationships within the data. Examples include clustering (grouping similar data points together) and dimensionality reduction (reducing the number of variables while preserving important information).\n",
            "\n",
            "3. **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment. It receives rewards or penalties based on its actions and learns to maximize its cumulative reward. Examples include game playing (e.g., AlphaGo) and robotics control.\n",
            "\n",
            "\n",
            "Relevance Score: 0.82\n",
            "Specificity Score: 0.68\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'relevance': 0.8201715, 'specificity': 0.6845637583892618}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def automated_evaluation(prompt, response, expected_content):\n",
        "    \"\"\"Perform automated evaluation of a prompt-response pair.\"\"\"\n",
        "    relevance = relevance_score(response, expected_content)\n",
        "    specificity = specificity_score(response)\n",
        "\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print(f\"\\nRelevance Score: {relevance:.2f}\")\n",
        "    print(f\"Specificity Score: {specificity:.2f}\")\n",
        "\n",
        "    return {\"relevance\": relevance, \"specificity\": specificity}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"What are the three main types of machine learning?\"\n",
        "expected_content = \"The three main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
        "response = llm.invoke(prompt).content\n",
        "automated_evaluation(prompt, response, expected_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparative Analysis\n",
        "\n",
        "Let's compare the effectiveness of different prompts for the same task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt: List the types of machine learning.\n",
            "Response: Machine learning can be broadly categorized in several ways, and these categories often overlap.  Here are some common types:\n",
            "\n",
            "**By Learning Style:**\n",
            "\n",
            "* **Supervised Learning:**  The algorithm learns from labeled data; it's given input data and corresponding correct outputs.  The goal is to learn a mapping from input to output.  Examples include:\n",
            "    * **Regression:** Predicting a continuous value (e.g., house price prediction).\n",
            "    * **Classification:** Predicting a categorical value (e.g., spam detection).\n",
            "\n",
            "* **Unsupervised Learning:** The algorithm learns from unlabeled data; it's given only input data and must find structure or patterns on its own. Examples include:\n",
            "    * **Clustering:** Grouping similar data points together (e.g., customer segmentation).\n",
            "    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., principal component analysis).\n",
            "    * **Association Rule Learning:** Discovering relationships between variables (e.g., market basket analysis).\n",
            "\n",
            "* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment. It receives rewards or penalties for its actions and learns to maximize its cumulative reward.  Examples include:\n",
            "    * **Game playing (e.g., AlphaGo)**\n",
            "    * **Robotics**\n",
            "    * **Resource management**\n",
            "\n",
            "\n",
            "**By Approach:**\n",
            "\n",
            "* **Batch Learning:** The algorithm is trained on a complete dataset at once.\n",
            "* **Online Learning:** The algorithm learns incrementally from new data as it arrives.\n",
            "* **Semi-supervised Learning:** The algorithm learns from a combination of labeled and unlabeled data.\n",
            "* **Self-supervised Learning:** The algorithm learns from unlabeled data by creating its own labels or tasks.  (A sub-type often considered under unsupervised learning)\n",
            "* **Transfer Learning:**  Knowledge gained from solving one problem is applied to a different but related problem.\n",
            "\n",
            "\n",
            "**By Algorithm Type (this is a very extensive list, these are just examples):**\n",
            "\n",
            "* **Decision Trees**\n",
            "* **Support Vector Machines (SVMs)**\n",
            "* **Naive Bayes**\n",
            "* **k-Nearest Neighbors (k-NN)**\n",
            "* **Neural Networks (including Deep Learning)**\n",
            "* **Linear Regression**\n",
            "* **Logistic Regression**\n",
            "* **Random Forests**\n",
            "* **Gradient Boosting Machines (GBMs)**\n",
            "\n",
            "\n",
            "It's important to note that these categories aren't mutually exclusive. For example, a neural network can be used for supervised, unsupervised, or reinforcement learning.  The best type of machine learning to use depends heavily on the specific problem and the available data.\n",
            "\n",
            "\n",
            "Relevance Score: 0.70\n",
            "Specificity Score: 0.62\n",
            "Prompt: What are the main categories of machine learning algorithms?\n",
            "Response: Machine learning algorithms can be broadly categorized into several main types, although there's some overlap and hybrid approaches:\n",
            "\n",
            "**1. Supervised Learning:**  Algorithms learn from labeled data, where each data point is tagged with the correct answer.  The goal is to learn a mapping from inputs to outputs.  Key subcategories include:\n",
            "\n",
            "* **Regression:** Predicts a continuous output variable.  Examples include linear regression, polynomial regression, support vector regression (SVR), and decision tree regression.\n",
            "* **Classification:** Predicts a categorical output variable.  Examples include logistic regression, support vector machines (SVM), decision trees, random forests, naive Bayes, and k-nearest neighbors (k-NN).\n",
            "\n",
            "\n",
            "**2. Unsupervised Learning:** Algorithms learn from unlabeled data, where there are no pre-assigned answers. The goal is to discover patterns, structures, or relationships in the data. Key subcategories include:\n",
            "\n",
            "* **Clustering:** Groups similar data points together.  Examples include k-means clustering, hierarchical clustering, DBSCAN.\n",
            "* **Dimensionality Reduction:** Reduces the number of variables while preserving important information. Examples include Principal Component Analysis (PCA), t-distributed Stochastic Neighbor Embedding (t-SNE).\n",
            "* **Association Rule Learning:** Discovers relationships between variables in large datasets.  Example: Apriori algorithm (often used in market basket analysis).\n",
            "\n",
            "\n",
            "**3. Reinforcement Learning:** Algorithms learn through trial and error by interacting with an environment.  The algorithm receives rewards or penalties based on its actions, and learns to maximize its cumulative reward.  Examples include Q-learning, SARSA.\n",
            "\n",
            "\n",
            "**4. Semi-supervised Learning:** Algorithms learn from a combination of labeled and unlabeled data. This is often used when labeled data is scarce or expensive to obtain.\n",
            "\n",
            "\n",
            "**5. Deep Learning:** A subfield of machine learning that uses artificial neural networks with multiple layers (hence \"deep\") to learn complex patterns from data.  This category encompasses many different architectures, including:\n",
            "\n",
            "* **Convolutional Neural Networks (CNNs):**  Excellent for image and video processing.\n",
            "* **Recurrent Neural Networks (RNNs):**  Well-suited for sequential data like text and time series.\n",
            "* **Generative Adversarial Networks (GANs):**  Used for generating new data instances that resemble the training data.\n",
            "* **Autoencoders:** Used for dimensionality reduction and feature extraction.\n",
            "\n",
            "\n",
            "It's important to note that these categories aren't mutually exclusive. For example, a deep learning model can be used for supervised learning (e.g., a CNN for image classification) or unsupervised learning (e.g., an autoencoder for dimensionality reduction).  The best algorithm choice depends heavily on the specific problem and the nature of the available data.\n",
            "\n",
            "\n",
            "Relevance Score: 0.73\n",
            "Specificity Score: 0.65\n",
            "Prompt: Explain the different approaches to machine learning.\n",
            "Response: Machine learning approaches can be categorized in several ways, but the most common distinctions are based on the **learning style** and the **type of learning problem**.\n",
            "\n",
            "**I. Based on Learning Style:**\n",
            "\n",
            "* **Supervised Learning:** This approach uses labeled data, meaning each data point is tagged with the correct answer (the \"label\"). The algorithm learns to map inputs to outputs based on this labeled data.  The goal is to build a model that can accurately predict the output for new, unseen inputs.  Examples include:\n",
            "    * **Regression:** Predicting a continuous output variable (e.g., predicting house prices, stock prices).  Algorithms include linear regression, support vector regression, decision trees.\n",
            "    * **Classification:** Predicting a categorical output variable (e.g., classifying emails as spam or not spam, identifying images of cats or dogs). Algorithms include logistic regression, support vector machines (SVMs), decision trees, naive Bayes.\n",
            "\n",
            "* **Unsupervised Learning:** This approach uses unlabeled data, meaning there are no pre-assigned labels. The algorithm aims to discover hidden patterns, structures, or relationships in the data. Examples include:\n",
            "    * **Clustering:** Grouping similar data points together (e.g., customer segmentation, anomaly detection). Algorithms include k-means, hierarchical clustering, DBSCAN.\n",
            "    * **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE)).  This simplifies data and improves model performance.\n",
            "    * **Association Rule Mining:** Discovering relationships between variables (e.g., market basket analysis \u2013 finding items frequently bought together).  Algorithms include Apriori, FP-Growth.\n",
            "\n",
            "* **Reinforcement Learning:** This approach involves an agent interacting with an environment. The agent learns to take actions that maximize a reward signal. It learns through trial and error, without explicit labels. Examples include:\n",
            "    * **Game playing (e.g., AlphaGo)**\n",
            "    * **Robotics**\n",
            "    * **Resource management**\n",
            "\n",
            "\n",
            "**II. Based on the Type of Learning Problem:**\n",
            "\n",
            "This categorization often overlaps with the learning style but emphasizes the nature of the task.\n",
            "\n",
            "* **Prediction:**  Forecasting future outcomes based on historical data (e.g., weather forecasting, sales prediction). This is commonly done using supervised learning techniques like regression.\n",
            "\n",
            "* **Classification:** Assigning data points to predefined categories (e.g., spam detection, image recognition). This is a core task of supervised learning.\n",
            "\n",
            "* **Clustering:** Grouping similar data points together without pre-defined categories (e.g., customer segmentation, anomaly detection). This is a core task of unsupervised learning.\n",
            "\n",
            "* **Anomaly Detection:** Identifying unusual or outlier data points (e.g., fraud detection, network intrusion detection). This can use both supervised and unsupervised techniques.\n",
            "\n",
            "\n",
            "**III. Other Important Distinctions:**\n",
            "\n",
            "* **Batch Learning:** The algorithm is trained on a complete dataset at once.\n",
            "* **Online Learning:** The algorithm is trained incrementally on new data points as they arrive.\n",
            "* **Semi-supervised Learning:** Uses a combination of labeled and unlabeled data. This is useful when labeled data is scarce.\n",
            "* **Transfer Learning:**  Leverages knowledge gained from solving one problem to improve performance on a related problem.  This reduces the need for large datasets for each new task.\n",
            "\n",
            "\n",
            "These categories are not mutually exclusive; many machine learning problems can be approached using multiple methods, and new approaches are constantly being developed. The choice of approach depends on the specific problem, the available data, and the desired outcome.\n",
            "\n",
            "\n",
            "Relevance Score: 0.64\n",
            "Specificity Score: 0.57\n",
            "Prompt Comparison Results:\n",
            "\n",
            "1. Prompt: What are the main categories of machine learning algorithms?\n",
            "   Relevance: 0.73\n",
            "   Specificity: 0.65\n",
            "\n",
            "2. Prompt: List the types of machine learning.\n",
            "   Relevance: 0.70\n",
            "   Specificity: 0.62\n",
            "\n",
            "3. Prompt: Explain the different approaches to machine learning.\n",
            "   Relevance: 0.64\n",
            "   Specificity: 0.57\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'prompt': 'What are the main categories of machine learning algorithms?',\n",
              "  'relevance': 0.73312235,\n",
              "  'specificity': 0.6455026455026455},\n",
              " {'prompt': 'List the types of machine learning.',\n",
              "  'relevance': 0.69804984,\n",
              "  'specificity': 0.617816091954023},\n",
              " {'prompt': 'Explain the different approaches to machine learning.',\n",
              "  'relevance': 0.6432309,\n",
              "  'specificity': 0.57421875}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compare_prompts(prompts, expected_content):\n",
        "    \"\"\"Compare the effectiveness of multiple prompts for the same task.\"\"\"\n",
        "    results = []\n",
        "    for prompt in prompts:\n",
        "        response = llm.invoke(prompt).content\n",
        "        evaluation = automated_evaluation(prompt, response, expected_content)\n",
        "        results.append({\"prompt\": prompt, **evaluation})\n",
        "\n",
        "    # Sort results by relevance score\n",
        "    sorted_results = sorted(results, key=lambda x: x[\"relevance\"], reverse=True)\n",
        "\n",
        "    print(\"Prompt Comparison Results:\")\n",
        "    for i, result in enumerate(sorted_results, 1):\n",
        "        print(f\"\\n{i}. Prompt: {result['prompt']}\")\n",
        "        print(f\"   Relevance: {result['relevance']:.2f}\")\n",
        "        print(f\"   Specificity: {result['specificity']:.2f}\")\n",
        "\n",
        "    return sorted_results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompts = [\n",
        "    \"List the types of machine learning.\",\n",
        "    \"What are the main categories of machine learning algorithms?\",\n",
        "    \"Explain the different approaches to machine learning.\",\n",
        "]\n",
        "expected_content = \"The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\"\n",
        "compare_prompts(prompts, expected_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Putting It All Together\n",
        "\n",
        "Now, let's create a comprehensive prompt evaluation function that combines both manual and automated techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Automated Evaluation:\n",
            "Prompt: Explain the concept of overfitting in machine learning.\n",
            "Response: Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data, it memorizes the specific details and noise present in the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\n",
            "\n",
            "Imagine you're trying to learn the relationship between hours studied and exam scores.  You have a small dataset.  An overfit model might perfectly capture every data point in your training set, perhaps even drawing a wildly complex curve that zig-zags through each point.  However, this complex curve is unlikely to accurately reflect the true relationship between studying and exam scores.  When presented with a new student's study hours, the model will likely give a wildly inaccurate prediction because it's focused on the quirks of the small training set rather than the broader pattern.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "* **High training accuracy, low test accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has seen but fails miserably on unseen data.\n",
            "\n",
            "* **Memorization, not generalization:** The model memorizes the training data instead of learning the underlying patterns.  It's like cramming for a test instead of understanding the concepts.\n",
            "\n",
            "* **Complexity of the model:** Overfitting is more likely with complex models (e.g., those with many parameters or high degrees of freedom).  A simple model might not capture all the nuances of the data, but it's less prone to overfitting.\n",
            "\n",
            "* **Insufficient data:**  Having too little training data relative to the complexity of the model increases the risk of overfitting.  The model doesn't have enough examples to learn the true underlying patterns and instead focuses on the limited examples it has.\n",
            "\n",
            "* **Noise in the data:**  If the training data contains significant noise (random errors or irrelevant information), a complex model might try to fit that noise, leading to overfitting.\n",
            "\n",
            "\n",
            "**Consequences of Overfitting:**\n",
            "\n",
            "* **Poor generalization:** The model fails to perform well on new, unseen data.\n",
            "* **Unreliable predictions:** Predictions are unreliable and not trustworthy.\n",
            "* **Waste of resources:**  A complex overfit model might require more computational resources and time to train without providing significant improvements in real-world performance.\n",
            "\n",
            "\n",
            "**Mitigation Techniques:**\n",
            "\n",
            "Several techniques can help prevent overfitting:\n",
            "\n",
            "* **Data augmentation:** Increasing the size of the training dataset with modified versions of existing data.\n",
            "* **Regularization:** Adding penalty terms to the model's loss function to discourage overly complex models.\n",
            "* **Cross-validation:** Evaluating the model's performance on multiple subsets of the data to get a more robust estimate of its generalization ability.\n",
            "* **Pruning (for decision trees):** Removing less important branches of a decision tree to simplify the model.\n",
            "* **Early stopping (for iterative methods):** Stopping the training process before the model starts to overfit.\n",
            "* **Feature selection/engineering:** Reducing the number of features or transforming them to improve model performance and reduce complexity.\n",
            "* **Using simpler models:** Opting for less complex models that are less prone to overfitting.\n",
            "\n",
            "\n",
            "By understanding overfitting and employing appropriate mitigation techniques, you can build more robust and reliable machine learning models that generalize well to new data.\n",
            "\n",
            "\n",
            "Relevance Score: 0.69\n",
            "Specificity Score: 0.53\n",
            "\n",
            "Manual Evaluation:\n",
            "Prompt: Explain the concept of overfitting in machine learning.\n",
            "Response: Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data, it memorizes the specific details and noise present in the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\n",
            "\n",
            "Imagine you're trying to learn the relationship between hours studied and exam scores.  You have a small dataset.  An overfit model might perfectly capture every data point in your training set, perhaps even drawing a wildly complex curve that zig-zags through each point.  However, this complex curve is unlikely to accurately reflect the true relationship between studying and exam scores.  When presented with a new student's study hours, the model will likely give a wildly inaccurate prediction because it's focused on the quirks of the small training set rather than the broader pattern.\n",
            "\n",
            "Here's a breakdown of the key aspects:\n",
            "\n",
            "* **High training accuracy, low test accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has seen but fails miserably on unseen data.\n",
            "\n",
            "* **Memorization, not generalization:** The model memorizes the training data instead of learning the underlying patterns.  It's like cramming for a test instead of understanding the concepts.\n",
            "\n",
            "* **Complexity of the model:** Overfitting is more likely with complex models (e.g., those with many parameters or high degrees of freedom).  A simple model might not capture all the nuances of the data, but it's less prone to overfitting.\n",
            "\n",
            "* **Insufficient data:**  Having too little training data relative to the complexity of the model increases the risk of overfitting.  The model doesn't have enough examples to learn the true underlying patterns and instead focuses on the limited examples it has.\n",
            "\n",
            "* **Noise in the data:**  If the training data contains significant noise (random errors or irrelevant information), a complex model might try to fit that noise, leading to overfitting.\n",
            "\n",
            "\n",
            "**Consequences of Overfitting:**\n",
            "\n",
            "* **Poor generalization:** The model fails to perform well on new, unseen data.\n",
            "* **Unreliable predictions:** Predictions are unreliable and not trustworthy.\n",
            "* **Waste of resources:**  A complex overfit model might require more computational resources and time to train without providing significant improvements in real-world performance.\n",
            "\n",
            "\n",
            "**Mitigation Techniques:**\n",
            "\n",
            "Several techniques can help prevent overfitting:\n",
            "\n",
            "* **Data augmentation:** Increasing the size of the training dataset with modified versions of existing data.\n",
            "* **Regularization:** Adding penalty terms to the model's loss function to discourage overly complex models.\n",
            "* **Cross-validation:** Evaluating the model's performance on multiple subsets of the data to get a more robust estimate of its generalization ability.\n",
            "* **Pruning (for decision trees):** Removing less important branches of a decision tree to simplify the model.\n",
            "* **Early stopping (for iterative methods):** Stopping the training process before the model starts to overfit.\n",
            "* **Feature selection/engineering:** Reducing the number of features or transforming them to improve model performance and reduce complexity.\n",
            "* **Using simpler models:** Opting for less complex models that are less prone to overfitting.\n",
            "\n",
            "\n",
            "By understanding overfitting and employing appropriate mitigation techniques, you can build more robust and reliable machine learning models that generalize well to new data.\n",
            "\n",
            "\n",
            "Evaluation Criteria:\n",
            "Clarity: 5.0/10\n",
            "Accuracy: 5.0/10\n",
            "Relevance: 5.0/10\n",
            "\n",
            "Additional Comments:\n",
            "Comments: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'prompt': 'Explain the concept of overfitting in machine learning.',\n",
              " 'response': \"Overfitting in machine learning occurs when a model learns the training data *too well*.  Instead of learning the underlying patterns and relationships in the data that generalize to unseen data, it memorizes the specific details and noise present in the training set.  This leads to excellent performance on the training data but poor performance on new, unseen data (the test data).\\n\\nImagine you're trying to learn the relationship between hours studied and exam scores.  You have a small dataset.  An overfit model might perfectly capture every data point in your training set, perhaps even drawing a wildly complex curve that zig-zags through each point.  However, this complex curve is unlikely to accurately reflect the true relationship between studying and exam scores.  When presented with a new student's study hours, the model will likely give a wildly inaccurate prediction because it's focused on the quirks of the small training set rather than the broader pattern.\\n\\nHere's a breakdown of the key aspects:\\n\\n* **High training accuracy, low test accuracy:** This is the hallmark of overfitting. The model performs exceptionally well on the data it has seen but fails miserably on unseen data.\\n\\n* **Memorization, not generalization:** The model memorizes the training data instead of learning the underlying patterns.  It's like cramming for a test instead of understanding the concepts.\\n\\n* **Complexity of the model:** Overfitting is more likely with complex models (e.g., those with many parameters or high degrees of freedom).  A simple model might not capture all the nuances of the data, but it's less prone to overfitting.\\n\\n* **Insufficient data:**  Having too little training data relative to the complexity of the model increases the risk of overfitting.  The model doesn't have enough examples to learn the true underlying patterns and instead focuses on the limited examples it has.\\n\\n* **Noise in the data:**  If the training data contains significant noise (random errors or irrelevant information), a complex model might try to fit that noise, leading to overfitting.\\n\\n\\n**Consequences of Overfitting:**\\n\\n* **Poor generalization:** The model fails to perform well on new, unseen data.\\n* **Unreliable predictions:** Predictions are unreliable and not trustworthy.\\n* **Waste of resources:**  A complex overfit model might require more computational resources and time to train without providing significant improvements in real-world performance.\\n\\n\\n**Mitigation Techniques:**\\n\\nSeveral techniques can help prevent overfitting:\\n\\n* **Data augmentation:** Increasing the size of the training dataset with modified versions of existing data.\\n* **Regularization:** Adding penalty terms to the model's loss function to discourage overly complex models.\\n* **Cross-validation:** Evaluating the model's performance on multiple subsets of the data to get a more robust estimate of its generalization ability.\\n* **Pruning (for decision trees):** Removing less important branches of a decision tree to simplify the model.\\n* **Early stopping (for iterative methods):** Stopping the training process before the model starts to overfit.\\n* **Feature selection/engineering:** Reducing the number of features or transforming them to improve model performance and reduce complexity.\\n* **Using simpler models:** Opting for less complex models that are less prone to overfitting.\\n\\n\\nBy understanding overfitting and employing appropriate mitigation techniques, you can build more robust and reliable machine learning models that generalize well to new data.\\n\",\n",
              " 'relevance': 0.6912272,\n",
              " 'specificity': 0.5321969696969697}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate_prompt(\n",
        "    prompt, expected_content, manual_criteria=[\"Clarity\", \"Accuracy\", \"Relevance\"]\n",
        "):\n",
        "    \"\"\"Perform a comprehensive evaluation of a prompt using both manual and automated techniques.\"\"\"\n",
        "    response = llm.invoke(prompt).content\n",
        "\n",
        "    print(\"Automated Evaluation:\")\n",
        "    auto_results = automated_evaluation(prompt, response, expected_content)\n",
        "\n",
        "    print(\"\\nManual Evaluation:\")\n",
        "    manual_evaluation(prompt, response, manual_criteria)\n",
        "\n",
        "    return {\"prompt\": prompt, \"response\": response, **auto_results}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Explain the concept of overfitting in machine learning.\"\n",
        "expected_content = \"Overfitting occurs when a model learns the training data too well, including its noise and fluctuations, leading to poor generalization on new, unseen data.\"\n",
        "evaluate_prompt(prompt, expected_content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
