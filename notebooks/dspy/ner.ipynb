{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DSPy: Named Entity Recognition\n",
        "\n",
        "This tutorial demonstrates how to perform entity extraction using the CoNLL-2003 dataset with DSPy. The focus is on extracting entities referring to people. \n",
        "\n",
        "We will:\n",
        "- Extract and label entities from the CoNLL-2003 dataset that refer to people.\n",
        "- Define a DSPy program for extracting entities that refer to people.\n",
        "- Optimize and evaluate the program on a subset of the CoNLL-2003 dataset.\n",
        "\n",
        "By the end of this tutorial, you'll understand how to structure tasks in DSPy using signatures and modules, evaluate your system's performance, and improve its quality with optimizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from os import getenv\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import dspy\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a69f56aab094245a54d6cfd3820bbe3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "677d7adebb7941b5a42be131114f4530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "588fd930c274468aa0f05bf4b84a8f73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9742d4fdfeb46b690e27f4b9ea319c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def extract_people_entities(data_row: Dict[str, Any]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extracts entities referring to people from a row of the CoNLL-2003 dataset.\n",
        "\n",
        "    Args:\n",
        "        data_row (Dict[str, Any]): A row from the dataset containing tokens and NER tags.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of tokens tagged as people.\n",
        "    \"\"\"\n",
        "\n",
        "    return [\n",
        "        token\n",
        "        for token, ner_tag in zip(data_row[\"tokens\"], data_row[\"ner_tags\"])\n",
        "        if ner_tag in (1, 2)  # CoNLL entity codes 1 and 2 refer to people\n",
        "    ]\n",
        "\n",
        "\n",
        "def prepare_dataset(data_split, start: int, end: int) -> List[dspy.Example]:\n",
        "    \"\"\"\n",
        "    Prepares a sliced dataset split for use with DSPy.\n",
        "\n",
        "    Args:\n",
        "        data_split: The dataset split (e.g., train or test).\n",
        "        start (int): Starting index of the slice.\n",
        "        end (int): Ending index of the slice.\n",
        "\n",
        "    Returns:\n",
        "        List[dspy.Example]: List of DSPy Examples with tokens and expected labels.\n",
        "    \"\"\"\n",
        "\n",
        "    return [\n",
        "        dspy.Example(\n",
        "            tokens=row[\"tokens\"], expected_extracted_people=extract_people_entities(row)\n",
        "        ).with_inputs(\"tokens\")\n",
        "        for row in data_split.select(range(start, end))\n",
        "    ]\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "\n",
        "# Prepare the training and test sets\n",
        "train_set = prepare_dataset(dataset[\"train\"], 0, 50)\n",
        "test_set = prepare_dataset(dataset[\"test\"], 0, 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure DSPy and create an Entity Extraction Program\n",
        "\n",
        "Here, we define a DSPy program for extracting entities referring to people from tokenized text.\n",
        "\n",
        "Key DSPy concepts:\n",
        "- Signatures: Define structured input/output schemas for your program.\n",
        "- Modules: Encapsulate program logic in reusable, composable units. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PeopleExtraction(dspy.Signature):\n",
        "    \"\"\"\n",
        "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
        "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
        "    \"\"\"\n",
        "\n",
        "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
        "    extracted_people: list[str] = dspy.OutputField(\n",
        "        desc=\"all tokens referring to specific people extracted from the tokenized text\"\n",
        "    )\n",
        "\n",
        "\n",
        "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "lm = dspy.LM(\n",
        "    model=\"openrouter/azure/gpt-4o\",\n",
        "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
        "    base_url=getenv(\"OPENROUTER_BASE_URL\"),\n",
        ")\n",
        "dspy.settings.configure(lm=lm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    reasoning='The text mentions two specific people, \"John\" and \"Mary\". These are proper nouns and clearly refer to individuals. Other tokens like \"dog\" do not refer to people, so they are excluded.',\n",
              "    extracted_people=['John', 'Mary']\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "people_extractor(\n",
        "    tokens=[\n",
        "        \"John\",\n",
        "        \"is\",\n",
        "        \"going\",\n",
        "        \"to\",\n",
        "        \"the\",\n",
        "        \"store\",\n",
        "        \"with\",\n",
        "        \"Mary\",\n",
        "        \"and\",\n",
        "        \"their\",\n",
        "        \"dog\",\n",
        "        \".\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[34m[2025-03-17T14:25:20.985169]\u001b[0m\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `tokens` (list[str]): tokenized text\n",
            "\n",
            "Your output fields are:\n",
            "1. `reasoning` (str)\n",
            "2. `extracted_people` (list[str]): all tokens referring to specific people extracted from the tokenized text\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "{tokens}\n",
            "\n",
            "[[ ## reasoning ## ]]\n",
            "{reasoning}\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "{extracted_people}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
            "        Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"John\", \"is\", \"going\", \"to\", \"the\", \"store\", \"with\", \"Mary\", \"and\", \"their\", \"dog\", \".\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## reasoning ## ]]\n",
            "The text mentions two specific people, \"John\" and \"Mary\". These are proper nouns and clearly refer to individuals. Other tokens like \"dog\" do not refer to people, so they are excluded.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[\"John\", \"Mary\"]\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dspy.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Metric and Evaluation Functions\n",
        "\n",
        "In DSPy, evaluating a program's performance is critical for iterative development. A good evaluation framework allows us to:\n",
        "\n",
        "- Measure the quality of our program's outputs.\n",
        "- Compare outputs against ground-truth labels.\n",
        "- Identify areas for improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extraction_correctness_metric(\n",
        "    example: dspy.Example, prediction: dspy.Prediction, trace=None\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Computes correctness of entity extraction predictions.\n",
        "\n",
        "    Args:\n",
        "        example (dspy.Example): The dataset example containing expected people entities.\n",
        "        prediction (dspy.Prediction): The prediction from the DSPy people extraction program.\n",
        "        trace: Optional trace object for debugging.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if predictions match expectations, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    return prediction.extracted_people == example.expected_extracted_people\n",
        "\n",
        "\n",
        "evaluate_correctness = dspy.Evaluate(\n",
        "    devset=test_set,\n",
        "    metric=extraction_correctness_metric,\n",
        "    num_threads=24,\n",
        "    display_progress=True,\n",
        "    display_table=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 196.00 / 200 (98.0%): : 202it [02:31,  1.33it/s]                       "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/03/17 14:28:02 INFO dspy.evaluate.evaluate: Average Metric: 196 / 200 (98.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>expected_extracted_people</th>\n",
              "      <th>reasoning</th>\n",
              "      <th>extracted_people</th>\n",
              "      <th>extraction_correctness_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
              "      <td>[CHINA]</td>\n",
              "      <td>The tokenized text does not contain any references to specific peo...</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>The tokens \"Nadim\" and \"Ladki\" appear to form a name referring to ...</td>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
              "      <td>[]</td>\n",
              "      <td>The tokens provided appear to describe a location and a date, but ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
              "      <td>[]</td>\n",
              "      <td>The tokenized text describes a sports event involving Japan and Sy...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>The tokenized text describes a soccer match involving China and Uz...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
              "      <td>[David, Campese]</td>\n",
              "      <td>The text mentions \"David Campese\" as a specific person, referring ...</td>\n",
              "      <td>[David, Campese]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
              "      <td>[]</td>\n",
              "      <td>The tokenized text mentions \"the 34-year-old winger,\" but it does ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
              "      <td>[Campese, Rob, Andrew]</td>\n",
              "      <td>The text mentions two specific individuals: \"Campese\" and \"Rob And...</td>\n",
              "      <td>[Campese, Rob, Andrew]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
              "      <td>[Campo, Andrew]</td>\n",
              "      <td>The text mentions two specific people: \"Campo\" and \"Andrew.\" These...</td>\n",
              "      <td>[Campo, Andrew]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
              "      <td>[]</td>\n",
              "      <td>The tokenized text mentions countries such as \"Italy,\" \"Scotland,\"...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows \u00d7 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                    tokens  \\\n",
              "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
              "1                                                           [Nadim, Ladki]   \n",
              "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
              "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
              "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
              "..                                                                     ...   \n",
              "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
              "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
              "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
              "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
              "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
              "\n",
              "    expected_extracted_people  \\\n",
              "0                     [CHINA]   \n",
              "1              [Nadim, Ladki]   \n",
              "2                          []   \n",
              "3                          []   \n",
              "4                          []   \n",
              "..                        ...   \n",
              "195          [David, Campese]   \n",
              "196                        []   \n",
              "197    [Campese, Rob, Andrew]   \n",
              "198           [Campo, Andrew]   \n",
              "199                        []   \n",
              "\n",
              "                                                                 reasoning  \\\n",
              "0    The tokenized text does not contain any references to specific peo...   \n",
              "1    The tokens \"Nadim\" and \"Ladki\" appear to form a name referring to ...   \n",
              "2    The tokens provided appear to describe a location and a date, but ...   \n",
              "3    The tokenized text describes a sports event involving Japan and Sy...   \n",
              "4    The tokenized text describes a soccer match involving China and Uz...   \n",
              "..                                                                     ...   \n",
              "195  The text mentions \"David Campese\" as a specific person, referring ...   \n",
              "196  The tokenized text mentions \"the 34-year-old winger,\" but it does ...   \n",
              "197  The text mentions two specific individuals: \"Campese\" and \"Rob And...   \n",
              "198  The text mentions two specific people: \"Campo\" and \"Andrew.\" These...   \n",
              "199  The tokenized text mentions countries such as \"Italy,\" \"Scotland,\"...   \n",
              "\n",
              "           extracted_people extraction_correctness_metric  \n",
              "0                        []                                \n",
              "1            [Nadim, Ladki]                     \u2714\ufe0f [True]  \n",
              "2                        []                     \u2714\ufe0f [True]  \n",
              "3                        []                     \u2714\ufe0f [True]  \n",
              "4                        []                     \u2714\ufe0f [True]  \n",
              "..                      ...                           ...  \n",
              "195        [David, Campese]                     \u2714\ufe0f [True]  \n",
              "196                      []                     \u2714\ufe0f [True]  \n",
              "197  [Campese, Rob, Andrew]                     \u2714\ufe0f [True]  \n",
              "198         [Campo, Andrew]                     \u2714\ufe0f [True]  \n",
              "199                      []                     \u2714\ufe0f [True]  \n",
              "\n",
              "[200 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "98.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_correctness(people_extractor, devset=test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimize the Model\n",
        "\n",
        "DSPy includes powerful optimizers that can improve the quality of your system.\n",
        "\n",
        "Here, we use DSPy's MIPROv2 optimizer to:\n",
        "- Automatically tune the program's language model (LM) prompt by 1. using the LM to adjust the prompt's instructions and 2. building few-shot examples from the training dataset that are augmented with reasoning generated from `dspy.ChainOfThought`.\n",
        "- Maximize correctness on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
            "num_trials: 25\n",
            "minibatch: False\n",
            "num_candidates: 19\n",
            "valset size: 40\n",
            "\n",
            "2025/01/17 07:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/01/17 07:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/01/17 07:50:00 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=19 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/19\n",
            "Bootstrapping set 2/19\n",
            "Bootstrapping set 3/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:06<00:09,  1.54s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
            "Bootstrapping set 4/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:03<00:04,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
            "Bootstrapping set 5/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:03<00:12,  1.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 6/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 619.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 7/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|\u2588         | 1/10 [00:00<00:00, 471.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 8/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 727.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 9/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|\u2588\u2588\u2588       | 3/10 [00:00<00:00, 946.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
            "Bootstrapping set 10/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|\u2588         | 1/10 [00:02<00:18,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 11/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|\u2588\u2588\u2588       | 3/10 [00:01<00:04,  1.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
            "Bootstrapping set 12/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 427.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 13/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|\u2588\u2588\u2588       | 3/10 [00:01<00:03,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
            "Bootstrapping set 14/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 660.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 15/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|\u2588         | 1/10 [00:00<00:00, 665.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 16/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|\u2588         | 1/10 [00:00<00:00, 669.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 17/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|\u2588\u2588\u2588       | 3/10 [00:00<00:00, 481.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
            "Bootstrapping set 18/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 914.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
            "Bootstrapping set 19/19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00, 992.09it/s]\n",
            "2025/01/17 07:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/01/17 07:50:18 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:50:27 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing instructions...\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
            "Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Identify all contiguous tokens that represent the full names of individuals mentioned in the provided text. Return these tokens as a list. Do not combine multiple tokens, and focus solely on person names, excluding organizations, locations, or other entities.  Provide a step-by-step rationale explaining your selections.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a highly specialized AI tasked with identifying individuals mentioned in breaking news articles for a global news agency.  Accuracy is paramount, as misidentification could lead to significant misinformation. Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens. Output a list of the extracted tokens. Do not combine multiple tokens into a single value.  Your performance directly impacts the agency's credibility and the public's trust, so ensure only actual person names are extracted.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Identify and extract all contiguous tokens that represent the full names of people mentioned in the provided text.  Output these tokens as a list of strings. Do not combine multiple tokens into a single value. If no person's name is found, return an empty list. Provide a step-by-step rationale explaining your decisions. Focus on extracting full names, and avoid extracting titles, roles, or other descriptive terms that are not part of a person's name.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are a meticulous named entity recognition expert specializing in identifying individuals mentioned in news articles, particularly those related to political and economic contexts.  Your task is to analyze the provided list of string tokens (words) from a news sentence and extract all contiguous tokens that refer to specific people.\n",
            "\n",
            "Focus solely on identifying individual names and avoid extracting other entities like organizations, locations, or titles.  Pay close attention to full names, which may span multiple tokens, and handle cases of repeated name occurrences accurately.  Output the identified person names as a list of individual tokens. Do not combine multiple tokens into a single string.\n",
            "\n",
            "For example, if the input is [\"President\", \"Joe\", \"Biden\", \"met\", \"with\", \"Chancellor\", \"Merkel\"], your output should be [\"Joe\", \"Biden\", \"Merkel\"].\n",
            "\n",
            "Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
            "Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Identify and extract all tokens that comprise the full names of people mentioned in the provided text.  Do not include titles, organizations, or locations.  If no person is mentioned, return an empty list.  Provide a step-by-step rationale explaining your selections, including why certain tokens were included or excluded.  Output a list of the extracted tokens.  Do not combine multiple tokens into a single value.  Focus solely on individual people's names.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 6: A critical news report is being prepared, and its accuracy hinges on correctly identifying all individuals mentioned.  Extract contiguous tokens referring to specific people, if any, from the following list of string tokens.  Failure to accurately identify all individuals could lead to misrepresentation of the report and significant consequences. Output a list of tokens.  In other words, do not combine multiple tokens into a single value.  Provide a clear rationale for your selections, outlining the reasoning behind each identified person. Double-check your work to ensure no individuals are missed.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 7: You are a highly specialized AI tasked with identifying individuals mentioned in sensitive intelligence reports. Accurate extraction is crucial for national security.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Any missed or falsely identified individuals could have severe consequences. Output a list of tokens.  Do not combine multiple tokens into a single value. Provide a clear, step-by-step rationale explaining your choices.  The fate of the mission depends on your accuracy.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 8: You are a Named Entity Recognition (NER) system specifically designed to extract the full names of people from tokenized text, primarily within the context of news articles, especially those focusing on political or economic topics.  You will receive a list of string tokens as input. Your task is to identify and extract all contiguous tokens that represent the full name of a person.\n",
            "\n",
            "**Input Format:** A list of strings, where each string represents a single token.\n",
            "\n",
            "**Output Format:**\n",
            "* **Reasoning:** A detailed explanation of your step-by-step reasoning process for identifying the extracted names. Begin this section with the phrase: \"Let's think step by step in order to\". Clearly state whether any names were found, and if so, list the identified names.  If no names are found, explicitly state that no people were identified.\n",
            "* **Extracted People:** A list of strings, where each string is a token that is part of a recognized person's name.  Only include tokens that are part of a full name. Do *not* combine multiple tokens into a single string.  If no people are found, return an empty list.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "* **Context is Key:**  The provided text will often be from news articles related to politics or economics. Consider this context when identifying names.\n",
            "* **Full Names:** Focus on extracting *full* names. Avoid extracting titles (e.g., \"President,\" \"Mr.\"),  or individual name components if the full name is available.\n",
            "* **Contiguous Tokens:** Extracted names must consist of contiguous tokens. Do not extract names where the tokens are separated by other words.\n",
            "* **Multiple Occurrences:** If a person's name appears multiple times, extract all occurrences, ensuring each instance is represented as a separate contiguous sequence of tokens.\n",
            "* **No Partial Names:** Do not extract partial names or single name components unless it is the only available form of the name.\n",
            "* **Accuracy is Crucial:** Prioritize accuracy over completeness. It is better to miss a name than to extract an incorrect sequence of tokens.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 9: A critical news article is being prepared for publication, and its accuracy hinges on correctly identifying all individuals mentioned.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Failure to accurately identify all individuals could lead to misrepresentation and damage the publication's credibility. Output a list of tokens.  Do not combine multiple tokens into a single value.  Provide a step-by-step rationale explaining your choices.  The integrity of the news article depends on your precision!\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 10: Identify and extract all contiguous tokens that represent the full names of people mentioned in the provided text. Return these tokens as a list. Do not combine multiple tokens. If no person names are found, return an empty list.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 11: You are a highly specialized AI tasked with identifying individuals mentioned in sensitive intelligence reports. Accurate extraction is crucial for national security.  Extract contiguous tokens referring to specific people, if any, from the list of string tokens provided. Output ONLY a list of the extracted person tokens. Do NOT combine multiple tokens into a single value. Failure to correctly identify individuals could have severe consequences.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 12: A critical international negotiation hinges on identifying key individuals involved.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Accuracy is paramount, as misidentification could jeopardize the entire process. Output a list of tokens. Do not combine multiple tokens into a single value. The fate of the negotiation rests on your ability to correctly identify the individuals involved.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 13: You are a highly specialized AI tasked with identifying individuals mentioned in sensitive intelligence reports. Accurate extraction is crucial for national security.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Any missed or falsely identified individuals could have severe consequences. Output a list of tokens.  Do not combine multiple tokens into a single value. Provide a clear, step-by-step rationale explaining your choices.  The fate of the mission depends on your accuracy.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 14: You are a meticulous editor specializing in identifying individuals mentioned in news articles.  Extract contiguous tokens referring to specific people, if any, from the list of string tokens provided. Output a list of tokens.  Do not combine multiple tokens into a single value, even if they form a complete name.  Focus solely on individual people, excluding organizations, locations, or other entities.  Provide a clear, step-by-step rationale explaining your choices.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 15: Extract all contiguous tokens that represent the full names of individuals mentioned in the provided tokenized text.  Focus on identifying people's names within a political/economic context, as the text is likely to be news-related.  Do not include tokens referring to organizations, locations, or other entities. Output a list of the extracted person name tokens.  Provide a step-by-step rationale explaining your reasoning for each extraction, clearly indicating why you believe each identified token belongs to a person's name and why any rejected tokens were not considered to be part of a person's name.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 16: You are a world-class journalist specializing in political and economic news analysis.  Your expertise lies in identifying key individuals involved in events.\n",
            "\n",
            "Extract contiguous tokens referring to specific people, if any, from a list of string tokens. Output a list of tokens. In other words, do not combine multiple tokens into a single value.  Focus on identifying individuals within the context of political or economic news.  Consider that the input text might be an excerpt from a news article.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 17: You are a highly skilled AI tasked with identifying individuals mentioned in critical news reports.  Accurately extracting these names is crucial for a sensitive international investigation, where missing a single name could compromise the entire operation.  Any oversight could have severe consequences.\n",
            "\n",
            "Given a list of string tokens representing a sentence from a news article, extract all contiguous tokens that refer to specific people.  Output these tokens as a list. Do not combine multiple tokens into a single value.  If no people are mentioned, return an empty list.  The success of this investigation depends on your precision and accuracy.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: 18: A critical international negotiation hinges on identifying key individuals involved.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Accuracy is paramount, as misidentification could jeopardize the entire process. Output a list of tokens; do not combine multiple tokens into a single value. The fate of the negotiations rests on your ability to correctly identify these individuals.\n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/01/17 07:53:16 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the default program...\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:16<00:00,  2.40it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:53:32 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:53:32 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 92.5\n",
            "\n",
            "2025/01/17 07:53:32 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/01/17 07:53:32 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "/Users/tangquocthai/Works/personal/vn-ds/.venv/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/01/17 07:53:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 1 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:14<00:00,  2.68it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:53:47 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 95.0\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 12', 'Predictor 0: Few-Shot Set 7'].\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0]\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 95.0\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.29it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:54:00 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:54:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 10', 'Predictor 0: Few-Shot Set 7'].\n",
            "2025/01/17 07:54:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0]\n",
            "2025/01/17 07:54:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 95.0\n",
            "2025/01/17 07:54:00 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:54:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.38it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:54:11 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 97.5\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5]\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:54:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  2.91it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:54:25 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:54:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 15', 'Predictor 0: Few-Shot Set 2'].\n",
            "2025/01/17 07:54:25 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0]\n",
            "2025/01/17 07:54:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:54:25 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:54:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.28it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:54:37 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:54:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:54:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5]\n",
            "2025/01/17 07:54:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:54:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:54:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 36.00 / 40 (90.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:15<00:00,  2.59it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:54:53 INFO dspy.evaluate.evaluate: Average Metric: 36 / 40 (90.0%)\n",
            "2025/01/17 07:54:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 90.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/01/17 07:54:53 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0]\n",
            "2025/01/17 07:54:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:54:53 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:54:53 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  2.88it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:55:07 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:55:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 12'].\n",
            "2025/01/17 07:55:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0]\n",
            "2025/01/17 07:55:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:55:07 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:55:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  2.94it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:55:20 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:55:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 11', 'Predictor 0: Few-Shot Set 13'].\n",
            "2025/01/17 07:55:20 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0]\n",
            "2025/01/17 07:55:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:55:20 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:55:20 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:14<00:00,  2.67it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:55:35 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
            "2025/01/17 07:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5]\n",
            "2025/01/17 07:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
            "\n",
            "\n",
            "2025/01/17 07:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  3.00it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:55:49 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 14', 'Predictor 0: Few-Shot Set 1'].\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5]\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:00<00:00, 2207.15it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:55:49 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 7', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5]\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:55:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.13it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:02 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:56:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 6', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:56:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5]\n",
            "2025/01/17 07:56:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:02 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.45it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:13 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:56:13 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:56:13 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5]\n",
            "2025/01/17 07:56:13 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:13 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:13 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:16<00:00,  2.48it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:30 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:56:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 6'].\n",
            "2025/01/17 07:56:30 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5]\n",
            "2025/01/17 07:56:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:30 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  2.92it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:43 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 14'].\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5]\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:00<00:00, 3544.21it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:43 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 8', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5]\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.31it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:56:55 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:56:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 18', 'Predictor 0: Few-Shot Set 16'].\n",
            "2025/01/17 07:56:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5]\n",
            "2025/01/17 07:56:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:56:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:56:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 36.00 / 40 (90.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.50it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:57:07 INFO dspy.evaluate.evaluate: Average Metric: 36 / 40 (90.0%)\n",
            "2025/01/17 07:57:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 90.0 with parameters ['Predictor 0: Instruction 9', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/01/17 07:57:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0]\n",
            "2025/01/17 07:57:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:57:07 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:57:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:13<00:00,  2.95it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:57:21 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:57:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 13', 'Predictor 0: Few-Shot Set 17'].\n",
            "2025/01/17 07:57:21 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0]\n",
            "2025/01/17 07:57:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:57:21 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:57:21 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 20 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.61it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:57:32 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 17', 'Predictor 0: Few-Shot Set 15'].\n",
            "2025/01/17 07:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5]\n",
            "2025/01/17 07:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 21 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.35it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:57:44 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:57:44 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 18'].\n",
            "2025/01/17 07:57:44 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5, 97.5]\n",
            "2025/01/17 07:57:44 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:57:44 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:57:44 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 22 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 39.00 / 40 (97.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.40it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:57:55 INFO dspy.evaluate.evaluate: Average Metric: 39 / 40 (97.5%)\n",
            "2025/01/17 07:57:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 97.5 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
            "2025/01/17 07:57:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5, 97.5, 97.5]\n",
            "2025/01/17 07:57:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:57:55 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:57:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.32it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:58:07 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:58:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 10'].\n",
            "2025/01/17 07:58:07 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5, 97.5, 97.5, 95.0]\n",
            "2025/01/17 07:58:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:58:07 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:58:07 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 24 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 38.00 / 40 (95.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:12<00:00,  3.16it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:58:20 INFO dspy.evaluate.evaluate: Average Metric: 38 / 40 (95.0%)\n",
            "2025/01/17 07:58:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 95.0 with parameters ['Predictor 0: Instruction 16', 'Predictor 0: Few-Shot Set 4'].\n",
            "2025/01/17 07:58:20 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5, 97.5, 97.5, 95.0, 95.0]\n",
            "2025/01/17 07:58:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:58:20 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:58:20 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 25 / 25 =====\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 37.00 / 40 (92.5%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 40/40 [00:11<00:00,  3.35it/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:58:32 INFO dspy.evaluate.evaluate: Average Metric: 37 / 40 (92.5%)\n",
            "2025/01/17 07:58:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 92.5 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 9'].\n",
            "2025/01/17 07:58:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [92.5, 95.0, 95.0, 97.5, 95.0, 97.5, 90.0, 95.0, 95.0, 97.5, 92.5, 97.5, 97.5, 97.5, 92.5, 92.5, 97.5, 92.5, 90.0, 95.0, 92.5, 97.5, 97.5, 95.0, 95.0, 92.5]\n",
            "2025/01/17 07:58:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 97.5\n",
            "2025/01/17 07:58:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
            "\n",
            "\n",
            "2025/01/17 07:58:32 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 97.5!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mipro_optimizer = dspy.MIPROv2(\n",
        "    metric=extraction_correctness_metric,\n",
        "    auto=\"medium\",\n",
        ")\n",
        "optimized_people_extractor = mipro_optimizer.compile(\n",
        "    people_extractor,\n",
        "    trainset=train_set,\n",
        "    max_bootstrapped_demos=4,\n",
        "    requires_permission_to_run=False,\n",
        "    minibatch=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 196.00 / 200 (98.0%): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 200/200 [00:16<00:00, 12.14it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/01/17 07:59:01 INFO dspy.evaluate.evaluate: Average Metric: 196 / 200 (98.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>expected_extracted_people</th>\n",
              "      <th>rationale</th>\n",
              "      <th>extracted_people</th>\n",
              "      <th>extraction_correctness_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
              "      <td>[CHINA]</td>\n",
              "      <td>${[]}. We found no names of specific people in the input text. Alt...</td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>${[\"Nadim\", \"Ladki\"]}. We extract \"Nadim Ladki\" as a person's name.</td>\n",
              "      <td>[Nadim, Ladki]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
              "      <td>[]</td>\n",
              "      <td>${[]}. We did not find any mentions of individuals.</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
              "      <td>[]</td>\n",
              "      <td>${[]}. We found no people mentioned.  \"Japan\" and \"Syria\" are coun...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>We extracted no people.  There are no tokens that refer to specifi...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
              "      <td>[David, Campese]</td>\n",
              "      <td>${[\"David\", \"Campese\"]}. We extracted \"David Campese\" because it a...</td>\n",
              "      <td>[David, Campese]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
              "      <td>[]</td>\n",
              "      <td>We extracted no people.  While the text refers to a \"34-year-old w...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
              "      <td>[Campese, Rob, Andrew]</td>\n",
              "      <td>${[\"Campese\", \"Rob\", \"Andrew\"]}. We extracted \"Campese\" and \"Rob A...</td>\n",
              "      <td>[Campese, Rob, Andrew]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
              "      <td>[Campo, Andrew]</td>\n",
              "      <td>${[\"Campo\", \"Andrew\"]}. We extracted \"Campo\" and \"Andrew\" as they ...</td>\n",
              "      <td>[Campo, Andrew]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
              "      <td>[]</td>\n",
              "      <td>We extracted no people.  While countries are mentioned, no individ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>\u2714\ufe0f [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows \u00d7 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                    tokens  \\\n",
              "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
              "1                                                           [Nadim, Ladki]   \n",
              "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
              "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
              "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
              "..                                                                     ...   \n",
              "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
              "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
              "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
              "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
              "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
              "\n",
              "    expected_extracted_people  \\\n",
              "0                     [CHINA]   \n",
              "1              [Nadim, Ladki]   \n",
              "2                          []   \n",
              "3                          []   \n",
              "4                          []   \n",
              "..                        ...   \n",
              "195          [David, Campese]   \n",
              "196                        []   \n",
              "197    [Campese, Rob, Andrew]   \n",
              "198           [Campo, Andrew]   \n",
              "199                        []   \n",
              "\n",
              "                                                                 rationale  \\\n",
              "0    ${[]}. We found no names of specific people in the input text. Alt...   \n",
              "1      ${[\"Nadim\", \"Ladki\"]}. We extract \"Nadim Ladki\" as a person's name.   \n",
              "2                      ${[]}. We did not find any mentions of individuals.   \n",
              "3    ${[]}. We found no people mentioned.  \"Japan\" and \"Syria\" are coun...   \n",
              "4    We extracted no people.  There are no tokens that refer to specifi...   \n",
              "..                                                                     ...   \n",
              "195  ${[\"David\", \"Campese\"]}. We extracted \"David Campese\" because it a...   \n",
              "196  We extracted no people.  While the text refers to a \"34-year-old w...   \n",
              "197  ${[\"Campese\", \"Rob\", \"Andrew\"]}. We extracted \"Campese\" and \"Rob A...   \n",
              "198  ${[\"Campo\", \"Andrew\"]}. We extracted \"Campo\" and \"Andrew\" as they ...   \n",
              "199  We extracted no people.  While countries are mentioned, no individ...   \n",
              "\n",
              "           extracted_people extraction_correctness_metric  \n",
              "0                        []                                \n",
              "1            [Nadim, Ladki]                     \u2714\ufe0f [True]  \n",
              "2                        []                     \u2714\ufe0f [True]  \n",
              "3                        []                     \u2714\ufe0f [True]  \n",
              "4                        []                     \u2714\ufe0f [True]  \n",
              "..                      ...                           ...  \n",
              "195        [David, Campese]                     \u2714\ufe0f [True]  \n",
              "196                      []                     \u2714\ufe0f [True]  \n",
              "197  [Campese, Rob, Andrew]                     \u2714\ufe0f [True]  \n",
              "198         [Campo, Andrew]                     \u2714\ufe0f [True]  \n",
              "199                      []                     \u2714\ufe0f [True]  \n",
              "\n",
              "[200 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "98.0"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_correctness(optimized_people_extractor, devset=test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[34m[2025-01-17T07:59:01.772698]\u001b[0m\n",
            "\n",
            "\u001b[31mSystem message:\u001b[0m\n",
            "\n",
            "Your input fields are:\n",
            "1. `tokens` (list[str]): tokenized text\n",
            "\n",
            "Your output fields are:\n",
            "1. `rationale` (str): ${produce the extracted_people}. We ...\n",
            "2. `extracted_people` (list[str]): all tokens referring to specific people extracted from the tokenized text\n",
            "\n",
            "All interactions will be structured in the following way, with the appropriate values filled in.\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "{tokens}\n",
            "\n",
            "[[ ## rationale ## ]]\n",
            "{rationale}\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "{extracted_people}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "In adhering to this structure, your objective is: \n",
            "        You are a highly specialized AI tasked with identifying individuals mentioned in sensitive intelligence reports. Accurate extraction is crucial for national security.  Extract contiguous tokens referring to specific people, if any, from the provided list of string tokens.  Any missed or falsely identified individuals could have severe consequences. Output a list of tokens.  Do not combine multiple tokens into a single value. Provide a clear, step-by-step rationale explaining your choices.  The fate of the mission depends on your accuracy.\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"He\", \"said\", \"further\", \"scientific\", \"study\", \"was\", \"required\", \"and\", \"if\", \"it\", \"was\", \"found\", \"that\", \"action\", \"was\", \"needed\", \"it\", \"should\", \"be\", \"taken\", \"by\", \"the\", \"European\", \"Union\", \".\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rationale ## ]]\n",
            "We extracted no people. There are no tokens that refer to specific people.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[]\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"BRUSSELS\", \"1996-08-22\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rationale ## ]]\n",
            "${[]}. We found no people mentioned.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[]\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"Fischler\", \"proposed\", \"EU-wide\", \"measures\", \"after\", \"reports\", \"from\", \"Britain\", \"and\", \"France\", \"that\", \"under\", \"laboratory\", \"conditions\", \"sheep\", \"could\", \"contract\", \"Bovine\", \"Spongiform\", \"Encephalopathy\", \"(\", \"BSE\", \")\", \"--\", \"mad\", \"cow\", \"disease\", \".\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rationale ## ]]\n",
            "${[\"Fischler\"]}. We extract \"Fischler\" as a person's name.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[\"Fischler\"]\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"Germany\", \"'s\", \"representative\", \"to\", \"the\", \"European\", \"Union\", \"'s\", \"veterinary\", \"committee\", \"Werner\", \"Zwingmann\", \"said\", \"on\", \"Wednesday\", \"consumers\", \"should\", \"buy\", \"sheepmeat\", \"from\", \"countries\", \"other\", \"than\", \"Britain\", \"until\", \"the\", \"scientific\", \"advice\", \"was\", \"clearer\", \".\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mAssistant message:\u001b[0m\n",
            "\n",
            "[[ ## rationale ## ]]\n",
            "Werner Zwingmann. We extracted the name \"Werner Zwingmann\" from the provided text.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[\"Werner\", \"Zwingmann\"]\n",
            "\n",
            "[[ ## completed ## ]]\n",
            "\n",
            "\n",
            "\u001b[31mUser message:\u001b[0m\n",
            "\n",
            "[[ ## tokens ## ]]\n",
            "[\"Campese\", \"will\", \"be\", \"up\", \"against\", \"a\", \"familiar\", \"foe\", \"in\", \"the\", \"shape\", \"of\", \"Barbarians\", \"captain\", \"Rob\", \"Andrew\", \",\", \"the\", \"man\", \"who\", \"kicked\", \"Australia\", \"to\", \"defeat\", \"with\", \"a\", \"last-ditch\", \"drop-goal\", \"in\", \"the\", \"World\", \"Cup\", \"quarter-final\", \"in\", \"Cape\", \"Town\", \".\"]\n",
            "\n",
            "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
            "\n",
            "\n",
            "\u001b[31mResponse:\u001b[0m\n",
            "\n",
            "\u001b[32m[[ ## rationale ## ]]\n",
            "${[\"Campese\", \"Rob\", \"Andrew\"]}. We extracted \"Campese\" and \"Rob Andrew\" as the names of specific people.\n",
            "\n",
            "[[ ## extracted_people ## ]]\n",
            "[\"Campese\", \"Rob\", \"Andrew\"]\n",
            "\n",
            "[[ ## completed ## ]]\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dspy.inspect_history(n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.6951775000000042"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cost = sum(\n",
        "    [x[\"cost\"] for x in lm.history if x[\"cost\"] is not None]\n",
        ")  # cost in USD, as calculated by LiteLLM for certain providers\n",
        "cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "source": [
        "## Saving and Loading Optimized Programs\n",
        "\n",
        "DSPy supports saving and loading programs, enabling you to reuse optimized systems without the need to re-optimize from scratch. This feature is especially useful for deploying your programs in production environments or sharing them with collaborators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Marcello', 'Cuttitta']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimized_people_extractor.save(\"optimized_extractor.json\")\n",
        "\n",
        "loaded_people_extractor = dspy.ChainOfThought(PeopleExtraction)\n",
        "loaded_people_extractor.load(\"optimized_extractor.json\")\n",
        "\n",
        "loaded_people_extractor(\n",
        "    tokens=[\"Italy\", \"recalled\", \"Marcello\", \"Cuttitta\"]\n",
        ").extracted_people"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
